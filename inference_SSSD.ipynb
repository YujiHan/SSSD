{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension for cauchy multiplication not found. Install by going to extensions/cauchy/ and running `python setup.py install`. This should speed up end-to-end training by 10-50%\n",
      "Falling back on slow Cauchy kernel. Install at least one of pykeops or the CUDA extension for efficiency.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils.util import get_mask_mnr, get_mask_bm, get_mask_rm\n",
    "from utils.util import find_max_epoch, print_size, sampling, calc_diffusion_hyperparams\n",
    "\n",
    "from imputers.SSSDS4Imputer import SSSDS4Imputer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global trainset_config\n",
    "global diffusion_hyperparams\n",
    "global model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {   \n",
    "    \"diffusion_config\":{\n",
    "        \"T\": 200,\n",
    "        \"beta_0\": 0.0001,\n",
    "        \"beta_T\": 0.02\n",
    "    },\n",
    "    \"wavenet_config\": {\n",
    "        \"in_channels\": 14, \n",
    "        \"out_channels\":14,\n",
    "        \"num_res_layers\": 36,\n",
    "        \"res_channels\": 256, \n",
    "        \"skip_channels\": 256,\n",
    "        \"diffusion_step_embed_dim_in\": 128,\n",
    "        \"diffusion_step_embed_dim_mid\": 512,\n",
    "        \"diffusion_step_embed_dim_out\": 512,\n",
    "        \"s4_lmax\": 100,\n",
    "        \"s4_d_state\":64,\n",
    "        \"s4_dropout\":0.0,\n",
    "        \"s4_bidirectional\":1,\n",
    "        \"s4_layernorm\":1\n",
    "    },\n",
    "    \"train_config\": {\n",
    "        \"output_directory\": \"./results/mujoco\",\n",
    "        \"ckpt_iter\": -1,\n",
    "        \"iters_per_ckpt\": 100,\n",
    "        \"iters_per_logging\": 100,\n",
    "        \"n_iters\": 150000,\n",
    "        \"learning_rate\": 2e-4,\n",
    "        \"only_generate_missing\": 1,\n",
    "        \"use_model\": 2,\n",
    "        \"masking\": \"rm\",\n",
    "        \"missing_k\": 90\n",
    "    },\n",
    "    \"trainset_config\":{\n",
    "        \"train_data_path\": \"/home/hanyuji/data/mujoco_dataset/train_mujoco.npy\",\n",
    "        \"test_data_path\": \"/home/hanyuji/data/mujoco_dataset/test_mujoco.npy\",\n",
    "        \"segment_length\":100,\n",
    "        \"sampling_rate\": 100\n",
    "    },\n",
    "    \"gen_config\":{\n",
    "        \"output_directory\": \"./results/mujoco_output\",\n",
    "        \"ckpt_path\": \"./results/mujoco/\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gen_config = config['gen_config']\n",
    "train_config = config[\"train_config\"]  # training parameters\n",
    "trainset_config = config[\"trainset_config\"]  # to load trainset\n",
    "diffusion_hyperparams = calc_diffusion_hyperparams(**config[\"diffusion_config\"])  # dictionary of all diffusion hyperparameters\n",
    "model_config = config['wavenet_config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGenerate data based on ground truth \\n\\nParameters:\\noutput_directory (str):           save generated speeches to this path\\nnum_samples (int):                number of samples to generate, default is 4\\nckpt_path (str):                  checkpoint path\\nckpt_iter (int or 'max'):         the pretrained checkpoint to be loaded; \\n                                    automitically selects the maximum iteration if 'max' is selected\\ndata_path (str):                  path to dataset, numpy array.\\nuse_model (int):                  0:DiffWave. 1:SSSDSA. 2:SSSDS4.\\nmasking (str):                    'mnr': missing not at random, 'bm': black-out, 'rm': random missing\\nonly_generate_missing (int):      0:all sample diffusion.  1:only apply diffusion to missing portions of the signal\\nmissing_k (int)                   k missing time points for each channel across the length.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_directory = \"./results/mujoco_output\"\n",
    "ckpt_path = \"./results/mujoco/\"\n",
    "num_samples = 500\n",
    "data_path = trainset_config[\"test_data_path\"]\n",
    "ckpt_iter = 'max'\n",
    "masking = train_config[\"masking\"]\n",
    "missing_k = train_config[\"missing_k\"]\n",
    "only_generate_missing = train_config[\"only_generate_missing\"]\n",
    "    \n",
    "\"\"\"\n",
    "Generate data based on ground truth \n",
    "\n",
    "Parameters:\n",
    "output_directory (str):           save generated speeches to this path\n",
    "num_samples (int):                number of samples to generate, default is 4\n",
    "ckpt_path (str):                  checkpoint path\n",
    "ckpt_iter (int or 'max'):         the pretrained checkpoint to be loaded; \n",
    "                                    automitically selects the maximum iteration if 'max' is selected\n",
    "data_path (str):                  path to dataset, numpy array.\n",
    "use_model (int):                  0:DiffWave. 1:SSSDSA. 2:SSSDS4.\n",
    "masking (str):                    'mnr': missing not at random, 'bm': black-out, 'rm': random missing\n",
    "only_generate_missing (int):      0:all sample diffusion.  1:only apply diffusion to missing portions of the signal\n",
    "missing_k (int)                   k missing time points for each channel across the length.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSSDS4Imputer Parameters: 48.371726M\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/mujoco/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# load checkpoint\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ckpt_iter \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 14\u001b[0m     ckpt_iter \u001b[38;5;241m=\u001b[39m \u001b[43mfind_max_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ckpt_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_iter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/sdb/hanyuji-workbench/scSSSD/utils/util.py:27\u001b[0m, in \u001b[0;36mfind_max_epoch\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_max_epoch\u001b[39m(path):\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    Find maximum epoch/iteration in path, formatted ${n_iter}.pkl\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    E.g. 100000.pkl\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    maximum iteration, -1 if there is no (valid) checkpoint\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/mujoco/'"
     ]
    }
   ],
   "source": [
    "# map diffusion hyperparameters to gpu\n",
    "for key in diffusion_hyperparams:\n",
    "    if key != \"T\":\n",
    "        diffusion_hyperparams[key] = diffusion_hyperparams[key].cuda()\n",
    "\n",
    "        \n",
    "# predefine model\n",
    "net = SSSDS4Imputer(**model_config).cuda()\n",
    "print_size(net)\n",
    "\n",
    "\n",
    "# load checkpoint\n",
    "if ckpt_iter == 'max':\n",
    "    ckpt_iter = find_max_epoch(ckpt_path)\n",
    "model_path = os.path.join(ckpt_path, f'{ckpt_iter}.pkl')\n",
    "try:\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f'Successfully loaded model at iteration {ckpt_iter}')\n",
    "except:\n",
    "    raise Exception('No valid model found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "### Custom data loading and reshaping ###\n",
    "\n",
    "testing_data = np.load(trainset_config['test_data_path'])\n",
    "testing_data = np.split(testing_data, 4, 0)\n",
    "testing_data = np.array(testing_data)\n",
    "testing_data = torch.from_numpy(testing_data).float().cuda()\n",
    "print('Data loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin sampling, total number of reverse steps = 200\n",
      "generated 500 utterances of random_digit at iteration 23500 in 273 seconds\n",
      "saved generated samples at iteration 23500\n",
      "begin sampling, total number of reverse steps = 200\n",
      "generated 500 utterances of random_digit at iteration 23500 in 270 seconds\n",
      "saved generated samples at iteration 23500\n",
      "begin sampling, total number of reverse steps = 200\n",
      "generated 500 utterances of random_digit at iteration 23500 in 261 seconds\n",
      "saved generated samples at iteration 23500\n",
      "begin sampling, total number of reverse steps = 200\n",
      "generated 500 utterances of random_digit at iteration 23500 in 261 seconds\n",
      "saved generated samples at iteration 23500\n",
      "Total MSE: 0.0046025217\n"
     ]
    }
   ],
   "source": [
    "all_mse = []\n",
    "\n",
    "\n",
    "for i, batch in enumerate(testing_data):\n",
    "\n",
    "    if masking == 'mnr':\n",
    "        mask_T = get_mask_mnr(batch[0], missing_k)\n",
    "        mask = mask_T.permute(1, 0)\n",
    "        mask = mask.repeat(batch.size()[0], 1, 1)\n",
    "        mask = mask.type(torch.float).cuda()\n",
    "\n",
    "    elif masking == 'bm':\n",
    "        mask_T = get_mask_bm(batch[0], missing_k)\n",
    "        mask = mask_T.permute(1, 0)\n",
    "        mask = mask.repeat(batch.size()[0], 1, 1)\n",
    "        mask = mask.type(torch.float).cuda()\n",
    "\n",
    "    elif masking == 'rm':\n",
    "        mask_T = get_mask_rm(batch[0], missing_k)\n",
    "        mask = mask_T.permute(1, 0)\n",
    "        mask = mask.repeat(batch.size()[0], 1, 1).float().cuda()\n",
    "\n",
    "        \n",
    "        \n",
    "    batch = batch.permute(0,2,1)\n",
    "    \n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "\n",
    "    sample_length = batch.size(2)\n",
    "    sample_channels = batch.size(1)\n",
    "    generated_audio = sampling(net, (num_samples, sample_channels, sample_length),\n",
    "                                diffusion_hyperparams,\n",
    "                                cond=batch,\n",
    "                                mask=mask,\n",
    "                                only_generate_missing=only_generate_missing)\n",
    "\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    print('generated {} utterances of random_digit at iteration {} in {} seconds'.format(num_samples,\n",
    "                                                                                            ckpt_iter,\n",
    "                                                                                            int(start.elapsed_time(\n",
    "                                                                                                end) / 1000)))\n",
    "\n",
    "    \n",
    "    generated_audio = generated_audio.detach().cpu().numpy()\n",
    "    batch = batch.detach().cpu().numpy()\n",
    "    mask = mask.detach().cpu().numpy() \n",
    "    \n",
    "    \n",
    "    outfile = f'imputation{i}.npy'\n",
    "    new_out = os.path.join(output_directory, outfile)\n",
    "    np.save(new_out, generated_audio)\n",
    "\n",
    "    outfile = f'original{i}.npy'  \n",
    "    new_out = os.path.join(output_directory, outfile)\n",
    "    np.save(new_out, batch)\n",
    "\n",
    "    outfile = f'mask{i}.npy'\n",
    "    new_out = os.path.join(output_directory, outfile)\n",
    "    np.save(new_out, mask)\n",
    "\n",
    "    print('saved generated samples at iteration %s' % ckpt_iter)\n",
    "    \n",
    "    mse = mean_squared_error(generated_audio[~mask.astype(bool)], batch[~mask.astype(bool)])\n",
    "    all_mse.append(mse)\n",
    "\n",
    "print('Total MSE:', mean(all_mse))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSSD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
